# -*- coding: utf-8 -*-
"""Data Transformation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aCaDUX7-LgspZoJLmfdQHh2dTvETbZMp
"""

! pip install bs4
! pip install lxml
import requests
import re
import pandas as pd
import time
import random
from datetime import date, timedelta
import pandas as pd
from urllib.parse import urljoin
import requests
from bs4 import BeautifulSoup as soup
from urllib.parse import urljoin
from bs4 import BeautifulSoup as bs
from selenium.webdriver.common.by import By

!apt-get install openjdk-8-jdk-headless -qq > /dev/null
!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz
!tar xf spark-3.1.1-bin-hadoop3.2.tgz
!pip install -q findspark

# Set environment
import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.1.1-bin-hadoop3.2"

import findspark
findspark.init()
from pyspark.sql import SparkSession

spark_jars = '/content/drive/MyDrive/Colab_Notebooks/postgresql-42.2.14.jar'

def get_spark(master="local[*]",name='DataEng'):
  builder = SparkSession.builder.appName(name)
  builder.config("spark.jars",spark_jars)
  return builder.getOrCreate()

spark = get_spark()
print(f'spark_session:{spark.version}')

# First etreieve parquet data
corrupt_control_score = spark.read.parquet('/content/corruption-control.parquet').toPandas()
government_effectiveness_score = spark.read.parquet('/content/govern_effective.parquet').toPandas()
regulation_quality_score = spark.read.parquet('/content/reg_quality.parquet').toPandas()
rule_law_score = spark.read.parquet('/content/rule_law.parquet').toPandas()
voice_accountability_score = spark.read.parquet('/content/voice_account.parquet').toPandas()
political_stab_score = spark.read.parquet('/content/political_stab.parquet').toPandas()

# Change column name according to DB diagram
corrupt_control_score.rename(columns={'corruption_control':'corruption_control_score'},inplace = True)
government_effectiveness_score.rename(columns={'corruption_control':'government_effectiveness_score'},inplace = True)
regulation_quality_score.rename(columns={'corruption_control':'regulation_quality_score'},inplace = True)
rule_law_score.rename(columns={'corruption_control':'rule_law_score'},inplace = True)
voice_accountability_score.rename(columns={'corruption_control':'voice_accountability_score'},inplace = True)
political_stab_score.rename(columns={'corruption_control':'political_stab_score'},inplace = True)

# Change column types based on DB diagram (remove "''" first before proceeding to change type)
corrupt_control_score=corrupt_control_score[(corrupt_control_score['corruption_control_score']!='')]
government_effectiveness_score = government_effectiveness_score[(government_effectiveness_score['government_effectiveness_score']!='')]
regulation_quality_score = regulation_quality_score[(regulation_quality_score['regulation_quality_score']!='')]
rule_law_score = rule_law_score[(rule_law_score['rule_law_score']!='')]
voice_accountability_score=voice_accountability_score[(voice_accountability_score['voice_accountability_score']!='')]
political_stab_score=political_stab_score[(political_stab_score['political_stab_score']!='')]

# Change datatype for all tables
corrupt_control_score = corrupt_control_score.astype({
    'country':'str',
    'country_code' : 'str',
    'year' : 'int',
    'corruption_control_score': 'float'
    })
government_effectiveness_score = government_effectiveness_score.astype({
    'country':'str',
    'country_code' : 'str',
    'year' : 'int', 
  'government_effectiveness_score':'float'  
})
regulation_quality_score = regulation_quality_score.astype({
    'country':'str',
    'country_code' : 'str',
    'year' : 'int',
    'regulation_quality_score':'float'
})
rule_law_score = rule_law_score.astype({
    'country':'str',
    'country_code' : 'str',
    'year' : 'int',  
    'rule_law_score':'float'
})
voice_accountability_score = voice_accountability_score.astype({
    'country':'str',
    'country_code' : 'str',
    'year' : 'int',    
    'voice_accountability_score':'float'
})
political_stab_score = political_stab_score.astype({
    'country':'str',
    'country_code' : 'str',
    'year' : 'int',    
    'political_stab_score':'float'
})

# Match the year from corruption data from corruption table (i.e. from 2017 to 2022)
def match_year(df):
  year = range(2017,2023)
  df = df[df['year'].isin(year)]
  return df
corrupt_control_score = match_year(corrupt_control_score)
government_effectiveness_score= match_year(government_effectiveness_score)
regulation_quality_score = match_year(regulation_quality_score)
rule_law_score = match_year(rule_law_score)
voice_accountability_score=match_year(voice_accountability_score)
political_stab_score= match_year(political_stab_score)

# Merge to form Indicator table
merge_columns = ['country','country_code','year']
Indicator = pd.merge(political_stab_score,
                     pd.merge(voice_accountability_score,
                     pd.merge(rule_law_score,
                     pd.merge(regulation_quality_score,
                     pd.merge(corrupt_control_score,government_effectiveness_score, 
                              on=merge_columns),on=merge_columns),
                              on=merge_columns),on=merge_columns),on=merge_columns)

# Find the percentage change of each indidcator group by country
Indicator['corrupt_control_score_pct'] = Indicator.groupby('country_code')['corruption_control_score'].pct_change(periods=-1).mul(100).fillna(0).round(2)
Indicator['government_effectiveness_score_pct'] = Indicator.groupby('country_code')['government_effectiveness_score'].pct_change(periods=-1).mul(100).fillna(0).round(2)
Indicator['regulation_quality_score_pct'] = Indicator.groupby('country_code')['regulation_quality_score'].pct_change(periods=-1).mul(100).fillna(0).round(2)
Indicator['rule_law_score_pct'] = Indicator.groupby('country_code')['rule_law_score'].pct_change(periods=-1).mul(100).fillna(0).round(2)
Indicator['voice_accountability_score_pct'] = Indicator.groupby('country_code')['voice_accountability_score'].pct_change(periods=-1).mul(100).fillna(0).round(2)
Indicator['cpolitical_stab_score_pct'] = Indicator.groupby('country_code')['political_stab_score'].pct_change(periods=-1).mul(100).fillna(0).round(2)

# Convert all the dataframe into parquet file
ccs_df = spark.createDataFrame(corrupt_control_score)
ges_df = spark.createDataFrame(government_effectiveness_score)
rqs_df = spark.createDataFrame(regulation_quality_score)
rls_df = spark.createDataFrame(rule_law_score)
vas_df = spark.createDataFrame(voice_accountability_score)
pss_df = spark.createDataFrame(political_stab_score)
Indicator = spark.createDataFrame(Indicator)

# Change datatype
# Indicators
ccs_df.printSchema()
ges_df.printSchema()
rqs_df.printSchema()
rls_df.printSchema()
vas_df.printSchema()
pss_df.printSchema()
Indicator.printSchema()

corrupt_df = spark.read.parquet('/content/corruption').toPandas()

print(corrupt_df.info())
# change column types 
corrupt_df= corrupt_df.astype({
    'country':'str',
    'rank' : 'int',
    'year' : 'int',    
    'corrupt_score':'float'
})
print(corrupt_df.dtypes)
# Create a spark dataframe
corruption = spark.createDataFrame(corrupt_df)
corruption.printSchema()

# Write all files into parquet format 
# Indicators
ccs_df.write.parquet('corruption-control.parquet',mode='overwrite')
ges_df.write.parquet('govern_effective.parquet',mode='overwrite')
pss_df.write.parquet('political_stab.parquet',mode='overwrite')
rls_df.write.parquet('rule_law.parquet',mode='overwrite')
rqs_df.write.parquet('reg_quality.parquet',mode='overwrite')
vas_df.write.parquet('voice_account.parquet',mode='overwrite')
Indicator.write.parquet('Indicator',mode='overwrite')
# Corruption
corruption.write.parquet("corruption",mode='overwrite')